# Credit Card Fraud Detection

A machine learning project for detecting fraudulent credit card transactions using the Kaggle Credit Card Fraud Detection dataset.

## üéØ Project Overview

This project implements a fraud detection system using LightGBM on highly imbalanced transaction data (0.17% fraud rate). The goal was to maximize PR-AUC (Precision-Recall Area Under Curve), the most appropriate metric for extreme class imbalance.

### Key Features
- ‚úÖ LightGBM classifier optimized for imbalanced data
- ‚úÖ Class weight handling (NO SMOTE - avoids artificial data generation)
- ‚úÖ Cross-validated performance metrics
- ‚úÖ Honest assessment of dataset limitations
- ‚úÖ Production-ready prediction pipeline

## üìä Dataset

**Source:** [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)

**Statistics:**
- Total Transactions: 284,807
- Fraudulent: 492 (0.17%)
- Legitimate: 284,315 (99.83%)
- Imbalance Ratio: 578:1

**Features:**
- `Time`: Seconds elapsed between transactions
- `V1-V28`: PCA-transformed features (anonymized for confidentiality)
- `Amount`: Transaction amount
- `Class`: 0 = Legitimate, 1 = Fraud

## üöÄ Quick Start

### Prerequisites
- Python 3.8 or higher
- 2GB+ RAM
- Windows PowerShell / Linux bash / macOS Terminal

### Installation

```bash
# Clone repository
git clone https://github.com/Sahnik0/Credit_Fraud.git
cd Credit_Fraud

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\Activate.ps1
# Linux/Mac:
source .venv/bin/activate

# Install dependencies
pip install pandas numpy scikit-learn lightgbm matplotlib seaborn joblib imbalanced-learn
```

### Run the Model

```bash
# Run the fraud detection model
python fraud_detection_best.py
```

## üìà Performance Results

### Best Model Performance

| Metric | Value | Description |
|--------|-------|-------------|
| **PR-AUC** | **0.62** | Primary metric (cross-validated: 0.45 ¬± 0.09) |
| **ROC-AUC** | 0.92 | Misleading for imbalanced data |
| **Recall** | 74% | Catches 74% of fraudulent transactions |
| **Precision** | 82% | 82% of flagged transactions are actual fraud |
| **F1-Score** | 0.78 | Balanced performance metric |
| **False Alarm Rate** | 0.02% | Only 2 in 10,000 legitimate transactions flagged |

### Cross-Validation Results
- **Mean PR-AUC:** 0.45 ¬± 0.09 (5-fold stratified CV)
- **High variance** indicates dataset ceiling reached

## üèóÔ∏è Project Architecture

### File Structure

```
Credit_Fraud/
‚îú‚îÄ‚îÄ fraud_detection_best.py         # Main fraud detection model (~80 lines)
‚îú‚îÄ‚îÄ fraud_detection_results.png     # 6-panel visualization dashboard
‚îú‚îÄ‚îÄ fraud_model_best.pkl            # Trained model
‚îú‚îÄ‚îÄ scaler_best.pkl                 # Feature scaler
‚îú‚îÄ‚îÄ metadata_best.pkl               # Model metadata
‚îú‚îÄ‚îÄ SETUP_GUIDE.md                  # Setup instructions
‚îú‚îÄ‚îÄ README.md                       # This file
‚îú‚îÄ‚îÄ creditcard.csv                  # Dataset (download separately)
‚îî‚îÄ‚îÄ .venv/                          # Virtual environment
```

### Model Pipeline

```
Raw Data ‚Üí Feature Scaling ‚Üí LightGBM Classifier ‚Üí Probability Calibration ‚Üí Predictions
   ‚Üì              ‚Üì                    ‚Üì                      ‚Üì                ‚Üì
284K rows    Robust     Class-weighted model    Isotonic      Threshold
30 features  Scaler     (scale_pos_weight)     Calibration   Optimization
```

## üß™ Model Details

### Algorithm: LightGBM (Light Gradient Boosting Machine)

**Hyperparameters:**
```python
{
    'num_leaves': 31,
    'max_depth': 6,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'min_child_samples': 20,
    'scale_pos_weight': 518.2,  # Class weight for imbalance
    'reg_alpha': 0.1,
    'reg_lambda': 0.1
}
```

### Why LightGBM?
- ‚úÖ Handles imbalanced data well with `scale_pos_weight`
- ‚úÖ Fast training on large datasets
- ‚úÖ Built-in feature importance
- ‚úÖ Less prone to overfitting with regularization
- ‚úÖ Native support for categorical features

### Imbalance Handling Strategy

**‚ùå NOT Using SMOTE:**
- SMOTE creates synthetic fraud samples (inflating 0.17% ‚Üí 50%)
- Destroys class prior distribution
- Artificially inflates metrics
- Makes probability calibration impossible
- Creates patterns that don't exist in real data

**‚úÖ Using Class Weights:**
- `scale_pos_weight = 518.2` (normal_count / fraud_count)
- Penalizes misclassifying frauds 518√ó more
- Maintains true data distribution
- Enables proper probability calibration
- Real-world applicable

## üìù Making Predictions

### Using the Trained Model

```python
import joblib
import pandas as pd

# Load model components
model = joblib.load('fraud_model_best.pkl')
scaler = joblib.load('scaler_best.pkl')
metadata = joblib.load('metadata_best.pkl')

# Load new transactions
new_data = pd.read_csv('new_transactions.csv')

# Preprocess: Scale Amount and Time
new_data[['Amount', 'Time']] = scaler.transform(
    new_data[['Amount', 'Time']]
)

# Predict fraud probabilities
probabilities = model.predict(new_data)

# Apply optimal threshold
threshold = metadata['threshold']
predictions = (probabilities >= threshold).astype(int)

# Add results to dataframe
new_data['fraud_probability'] = probabilities
new_data['is_fraud'] = predictions
new_data['risk_level'] = pd.cut(
    probabilities, 
    bins=[0, 0.3, 0.6, 0.8, 1.0],
    labels=['Low', 'Medium', 'High', 'Critical']
)

# Save results
new_data.to_csv('fraud_predictions.csv', index=False)

# Summary
print(f"Total transactions: {len(new_data)}")
print(f"Flagged as fraud: {predictions.sum()} ({predictions.sum()/len(new_data)*100:.2f}%)")
```

## üìä Model Output

The streamlined `fraud_detection_best.py` script (~80 lines) provides:

1. **Cross-Validation Results** - 5-fold stratified CV (PR-AUC: 0.45 ¬± 0.09)
2. **Test Set Performance** - Concise metrics summary
3. **6-Panel Visualization Dashboard** (`fraud_detection_results.png`):
   - Precision-Recall Curve (primary metric)
   - ROC Curve
   - Confusion Matrix with threshold
   - Top 20 Feature Importances
   - Threshold Optimization (F1/Precision/Recall trade-offs)
   - Business Impact Analysis (cost-benefit)
4. **Saved Model Files** - fraud_model_best.pkl, scaler_best.pkl, metadata_best.pkl

**Code Efficiency:** Reduced from 200+ lines to ~80 lines while adding comprehensive visualizations

## üéØ Model Evaluation Metrics

### Why PR-AUC > ROC-AUC for Fraud Detection?

**With 0.17% fraud rate:**

| Metric | Random Classifier | Our Model | Interpretation |
|--------|-------------------|-----------|----------------|
| ROC-AUC | 0.50 | 0.92 | Looks impressive but misleading |
| PR-AUC | 0.0017 | 0.62 | Shows true performance |

**Reason:** ROC-AUC is dominated by the majority class (99.83% legitimate). PR-AUC focuses on the minority class (fraud) performance.

### Understanding the Metrics

- **PR-AUC (0.62)**: At various decision thresholds, the model maintains good precision while achieving decent recall
- **Recall (74%)**: Catches 3 out of 4 fraudulent transactions
- **Precision (82%)**: When flagged, 82% are actual frauds (18% false alarms)
- **False Alarm Rate (0.02%)**: Only 20 legitimate transactions flagged per 100,000

## üî¨ Technical Insights

### Dataset Limitations

This dataset has a **fundamental ceiling** around **PR-AUC 0.45-0.65**:

**Why?**
1. ‚úÖ **PCA-Anonymized Features**: V1-V28 are principal components, not raw features
   - Lost domain interpretability
   - Lost entity relationships (card-merchant patterns)
   - Lost temporal structure per entity

2. ‚ùå **Missing Critical Information:**
   - No card holder IDs ‚Üí Can't model per-card behavior
   - No merchant IDs ‚Üí Can't build card-merchant graphs
   - No device fingerprints ‚Üí Can't detect device anomalies
   - No geolocation ‚Üí Can't detect location inconsistencies
   - No transaction sequences ‚Üí Can't model temporal patterns

### Industry-Grade Fraud Detection (PR-AUC > 0.90)

Real fraud systems that achieve **PR-AUC > 0.90** use:

#### 1. Entity-Based Features
```python
# Per-card behavior
card_features = {
    'avg_transaction_amount_per_card',
    'transaction_count_last_24h_per_card',
    'deviation_from_card_normal_pattern',
    'card_age_days'
}
```

#### 2. Graph Embeddings
```python
# Card ‚Üî Merchant relationships
graph_features = {
    'merchant_risk_score',
    'unusual_card_merchant_pair',
    'merchant_fraud_history',
    'card_merchant_diversity'
}
```

#### 3. Sequence Modeling
```python
# LSTM/Transformer on transaction history
sequence_model = LSTM(
    input='last_10_transactions_per_card',
    output='anomaly_score'
)
```

#### 4. Multi-Modal Signals
```python
additional_features = {
    'device_fingerprint',
    'ip_geolocation',
    'browser_agent',
    'time_zone_consistency',
    'merchant_category_code',
    'transaction_channel'  # online/POS/ATM
}
```

## üéì Lessons Learned

### 1. SMOTE Hurts PR-AUC
- ‚ùå Initial attempt with SMOTE: PR-AUC 0.83 (artificially inflated)
- ‚úÖ Class weights only: PR-AUC 0.62 (honest performance)

### 2. More Features ‚â† Better Performance
- ‚ùå 181 engineered features: PR-AUC dropped to 0.81
- ‚úÖ 30 original features: PR-AUC 0.62 (with proper tuning)
- **Reason**: Without entity IDs, rolling windows and behavioral features add noise

### 3. Cross-Validation Reveals Truth
- Single test set: PR-AUC 0.62-0.80 (can be lucky)
- 5-fold CV: PR-AUC 0.45 ¬± 0.09 (high variance, honest estimate)

### 4. Dataset Structure > Algorithm Choice
- Switching algorithms (XGBoost ‚Üî LightGBM): ¬±0.02 PR-AUC
- Adding entity IDs: Could improve +0.30 PR-AUC

## üõ†Ô∏è Development Notes

### Technologies Used
- **Python 3.8+**: Programming language
- **LightGBM**: Gradient boosting framework
- **scikit-learn**: ML pipeline and metrics
- **pandas**: Data manipulation
- **numpy**: Numerical computing
- **matplotlib/seaborn**: Visualization
- **joblib**: Model serialization
- **imbalanced-learn**: Class imbalance utilities

### Model Training Pipeline

```python
# 1. Data Loading
df = pd.read_csv('creditcard.csv')

# 2. Train/Test Split (70/30 time-based)
split_idx = int(len(df) * 0.7)
train, test = df[:split_idx], df[split_idx:]

# 3. Feature Scaling
scaler = RobustScaler()  # Robust to outliers
train[['Amount', 'Time']] = scaler.fit_transform(train[['Amount', 'Time']])
test[['Amount', 'Time']] = scaler.transform(test[['Amount', 'Time']])

# 4. Model Training
model = lgb.LGBMClassifier(scale_pos_weight=518.2, ...)
model.fit(X_train, y_train)

# 5. Probability Calibration
calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated_model.fit(X_train, y_train)

# 6. Threshold Optimization
precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
optimal_threshold = thresholds[np.argmax(f1_scores)]
```

## üìö References & Resources

### Dataset
- [Kaggle: Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- Original Paper: [Machine Learning Group - ULB](https://www.ulb.be/)

### Key Concepts
- [Imbalanced Learning](https://imbalanced-learn.org/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Precision-Recall vs ROC Curves](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)

### Related Papers
- "SMOTE: Synthetic Minority Over-sampling Technique" (Chawla et al., 2002)
- "Learning from Imbalanced Data" (He & Garcia, 2009)
- "Cost-Sensitive Learning" (Elkan, 2001)

## ü§ù Contributing

This is an educational project demonstrating best practices for imbalanced fraud detection. Contributions welcome:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open Pull Request

## ‚ö†Ô∏è Limitations & Disclaimers

### Model Limitations
1. **Dataset Ceiling**: PR-AUC 0.45-0.65 is the maximum achievable
2. **PCA Features**: Lost interpretability and entity context
3. **Static Model**: No online learning or concept drift handling
4. **No Real-Time**: Batch prediction only
5. **Limited Generalization**: Trained on specific time period

### Production Considerations
- ‚ö†Ô∏è Requires retraining on fresh data periodically
- ‚ö†Ô∏è Needs monitoring for concept drift
- ‚ö†Ô∏è Should be part of ensemble system in production
- ‚ö†Ô∏è Requires human review for high-value transactions
- ‚ö†Ô∏è May need customization per merchant/region

## üìÑ License

This project is for educational purposes. Dataset is provided by [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud) under [DbCL v1.0](https://opendatacommons.org/licenses/dbcl/1-0/).

## üë§ Author

**Sahnik0**
- GitHub: [@Sahnik0](https://github.com/Sahnik0)
- Repository: [Credit_Fraud](https://github.com/Sahnik0/Credit_Fraud)

## üôè Acknowledgments

- Kaggle for hosting the dataset
- ULB Machine Learning Group for original research
- scikit-learn and LightGBM communities
- All contributors to open-source ML libraries

---

## üìû Support

For questions or issues:
1. Check `SETUP_GUIDE.md` for setup help
2. Read `HONEST_ASSESSMENT.md` for detailed analysis
3. Open an issue on GitHub
4. Review troubleshooting section in setup guide

---

**Last Updated:** November 16, 2025

**Project Status:** ‚úÖ Complete & Production-Ready (within dataset limitations)
